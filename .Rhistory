labs(title="Average Recall Score between Feature Selection Methods and Algorithms",
x="Feature Selection Methods",
y="Recall Score") +
guides(fill=FALSE) +
theme_bw() +
scale_fill_grey() +
theme(axis.text.x=element_text(angle=45, hjust=1))
p1
#dev.off()
#png("idash_fa_f1sd.png", widt
#png("idash_fa_f1sd.png", width=1000, height=600, units="px", res=75)
feature_algorithm_sd <- subset(scoreTable, scoreTable$label=="label2" & scoreTable$metric=="recall" & scoreTable$avgOrSd=="sd")
p2 <- ggplot(feature_algorithm_sd, aes(x=feature, y=score, group=algorithm)) +
geom_line(aes(color=algorithm)) +
coord_cartesian(ylim=c(0.0, 0.4)) +
scale_y_continuous(breaks=seq(0.0, 0.4, 0.05)) +
labs(title="SD of Recall Score between Feature Selection Methods and Algorithms",
x="Feature Selection Methods",
y="Standard Deviation of Recall Score") +
guides(fill=FALSE) +
theme_bw() +
scale_fill_grey() +
theme(axis.text.x=element_text(angle=45, hjust=1))
p2
#png("idash_fa_acavg.png", width=1000, height=600, units="px", res=75)
feature_algorithm <- subset(scoreTable, scoreTable$label=="label2" & scoreTable$metric=="auc" & scoreTable$avgOrSd=="average")
p1 <- ggplot(feature_algorithm, aes(x=feature, y=score, group=algorithm)) +
geom_line(aes(color=algorithm)) +
coord_cartesian(ylim=c(0.85, 1.0)) +
scale_y_continuous(breaks=seq(0.85, 1.0, 0.01)) +
labs(title="Average AUC between Feature Selection Methods and Algorithms",
x="Feature Selection Methods",
y="AUC") +
guides(fill=FALSE) +
theme_bw() +
scale_fill_grey() +
theme(axis.text.x=element_text(angle=45, hjust=1))
p1
#dev.off()
#png("idash_fa_acavg.png", width=1000, height=600, units="px", res=75)
feature_algorithm <- subset(scoreTable, scoreTable$label=="label2" & scoreTable$metric=="auc" & scoreTable$avgOrSd=="average")
p1 <- ggplot(feature_algorithm, aes(x=feature, y=score, group=algorithm)) +
geom_line(aes(color=algorithm)) +
coord_cartesian(ylim=c(0.5, 0.8)) +
scale_y_continuous(breaks=seq(0.5, 0.8, 0.05)) +
labs(title="Average AUC between Feature Selection Methods and Algorithms",
x="Feature Selection Methods",
y="AUC") +
guides(fill=FALSE) +
theme_bw() +
scale_fill_grey() +
theme(axis.text.x=element_text(angle=45, hjust=1))
p1
#dev.off()
#png("idash_fa_accsd.png", width=1000, height=600, units="px", res=75)
feature_algorithm_sd <- subset(scoreTable, scoreTable$label=="label2" & scoreTable$metric=="auc" & scoreTable$avgOrSd=="sd")
p2 <- ggplot(feature_algorithm_sd, aes(x=feature, y=score, group=algorithm)) +
geom_line(aes(color=algorithm)) +
coord_cartesian(ylim=c(0.0, 0.15)) +
scale_y_continuous(breaks=seq(0.0, 0.15, 0.01)) +
labs(title="SD of AUC between Feature Selection Methods and Algorithms",
x="Feature Selection Methods",
y="Standard Deviation of AUC") +
guides(fill=FALSE) +
theme_bw() +
scale_fill_grey() +
theme(axis.text.x=element_text(angle=45, hjust=1))
p2
#dev.off()
#png("idash_fa_acavg.png", width=1000, height=600, units="px", res=75)
feature_algorithm <- subset(scoreTable, scoreTable$label=="label2" & scoreTable$metric=="accuracy" & scoreTable$avgOrSd=="average")
p1 <- ggplot(feature_algorithm, aes(x=feature, y=score, group=algorithm)) +
geom_line(aes(color=algorithm)) +
coord_cartesian(ylim=c(0.65, 1.0)) +
scale_y_continuous(breaks=seq(0.65, 1.0, 0.05)) +
labs(title="Average Accuracy between Feature Selection Methods and Algorithms",
x="Feature Selection Methods",
y="Accuracy") +
guides(fill=FALSE) +
theme_bw() +
scale_fill_grey() +
theme(axis.text.x=element_text(angle=45, hjust=1))
p1
#dev.off()
#png("idash_fa_acavg.png", width=1000, height=600, units="px", res=75)
feature_algorithm <- subset(scoreTable, scoreTable$label=="label2" & scoreTable$metric=="accuracy" & scoreTable$avgOrSd=="average")
p1 <- ggplot(feature_algorithm, aes(x=feature, y=score, group=algorithm)) +
geom_line(aes(color=algorithm)) +
coord_cartesian(ylim=c(0.5, 0.75)) +
scale_y_continuous(breaks=seq(0.5, 0.75, 0.05)) +
labs(title="Average Accuracy between Feature Selection Methods and Algorithms",
x="Feature Selection Methods",
y="Accuracy") +
guides(fill=FALSE) +
theme_bw() +
scale_fill_grey() +
theme(axis.text.x=element_text(angle=45, hjust=1))
p1
#dev.off()
#png("idash_fa_accsd.png", width=1000, height=600, units="px", res=75)
feature_algorithm_sd <- subset(scoreTable, scoreTable$label=="label2" & scoreTable$metric=="accuracy" & scoreTable$avgOrSd=="sd")
p2 <- ggplot(feature_algorithm_sd, aes(x=feature, y=score, group=algorithm)) +
geom_line(aes(color=algorithm)) +
coord_cartesian(ylim=c(0.0, 0.25)) +
scale_y_continuous(breaks=seq(0.0, 0.25, 0.05)) +
labs(title="SD of Accuracy between Feature Selection Methods and Algorithms",
x="Feature Selection Methods",
y="Standard Deviation of Accuracy") +
guides(fill=FALSE) +
theme_bw() +
scale_fill_grey() +
theme(axis.text.x=element_text(angle=45, hjust=1))
p2
#dev.off()
expDir = "~/Dropbox/rpdr/lmrNeuro_semgroupsnmf500_binary/"
cluster="nmf"
k=500
#
.packages = c("tm", "fpc", "cluster", "topicmodels", "lda", "NMF", "caret")
.inst = .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) suppressMessages(install.packages(.packages[!.inst], repos="http://cran.rstudio.com/"))
invisible(lapply(.packages, library, character.only=TRUE))
# k-mean clustering
X <- read.table(paste0(expDir, "analysis/freqTbl.txt"), stringsAsFactors=FALSE)
cl <- clustNMF(X, k)
file = X
matrix <- t(file)
V <- scale(matrix, center=F, scale=colSums(matrix))
k <- k # topic
fit.nmf <- nmf(matrix, k, 'lee') # 54.3 sec
is.na(matrix)
table(is.na(matrix))
fit.nmf <- nmf(matrix, k, 'lee') # 54.3 sec
dim(matrix)
matrix <- na.omit(matrix)
dim(matrix)
fit.nmf <- nmf(matrix, k, 'lee')
rowSums(matrix[, -1] > 0)
matrix <- matrix[rowSums(matrix[, -1] > 0) != 0, ]
dim(matrix)
fit.nmf <- nmf(matrix, k, 'lee')
matrix[, 1]
View(matrix)
matrix <- t(file)
V <- scale(matrix, center=F, scale=colSums(matrix))
k <- k # topic
View(matrix)
rowSums(matrix) != 0
matrix <- matrix[rowSums(matrix) != 0, ]
dim(matrix)
fit.nmf <- nmf(matrix, k, 'lee')
expDir = "~/Dropbox/rpdr/lmrNeuro_semgroupslda500_binary/"
.packages <- c("caret")
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) suppressMessages(install.packages(.packages[!.inst], repos="http://cran.rstudio.com/"))
invisible(lapply(.packages, library, character.only=TRUE))
X <- read.table(paste0(expDir, "analysis/freqTblCl.txt"), stringsAsFactors=FALSE)
y <- read.table(paste0(expDir, "analysis/label.txt"), sep="\t", stringsAsFactors=FALSE, header=FALSE)
labelPath = "~/Dropbox/rpdr/labelNeuro.txt"
multiclass = F
label <- levels(as.factor(unlist(class)))
class <- read.csv(labelPath, header=FALSE, stringsAsFactors=FALSE)
print("--- LOAD LABEL FILE FOR PROVIDED DATASET ---")
label <- levels(as.factor(unlist(class)))
labelBin <- data.frame(matrix(0, nrow=nrow(class), ncol=length(label)))
for (i in 1:length(label)) {
labelBin[, i] <- ifelse(grepl(label[i], class[, 1]), paste0("label", i), paste0("Xlabel", i))
}
write.table(labelBin, paste0(expDir, "analysis/label.txt"),
sep="\t", eol="\n", quote=FALSE, row.names=FALSE, col.names=FALSE)
# binary label reference
labelBinRef <- data.frame(matrix(NA, nrow=length(label), ncol=2))
for (i in 1:length(label)) {
labelBinRef[i, 1] <- label[i]
labelBinRef[i, 2] <- paste0("label", i)
}
write.table(labelBinRef, paste0(expDir, "analysis/labelRef.txt"),
sep="\t", eol="\n", quote=FALSE, row.names=FALSE, col.names=FALSE)
View(labelBinRef)
y <- read.table(paste0(expDir, "analysis/label.txt"), sep="\t", stringsAsFactors=FALSE, header=FALSE)
y <- read.table(paste0(expDir, "analysis/label.txt"), sep="\t", stringsAsFactors=FALSE, header=FALSE)
print(paste0("--- TOTAL ", length(X), " CONCEPTS AFTER USING ", cluster, " CLUSTERING METHOD ---"))
X$yLabel <- as.factor(y[, i])
X <- read.table(paste0(expDir, "analysis/freqTblCl.txt"), stringsAsFactors=FALSE)
X <- read.table(paste0(expDir, "analysis/freqTblCl.txt"), stringsAsFactors=FALSE)
X <- read.table(paste0(expDir, "analysis/freqTbl.txt"), stringsAsFactors=FALSE)
X <- read.table(paste0(expDir, "analysis/freqTblCl.txt"), stringsAsFactors=FALSE)
w2v = read.csv("~/Desktop/exp/idash_semgroups_binary/iDASHsemgroupsW2v.csv")
w2v = read.csv("~/Desktop/exp/idash_semgroups_binary/iDASHsemgroupsW2v.csv", sep="\t")
View(w2v)
load("~/_data/exj/exj.RData")
library(sqldf)
View(cstree)
View(dict_all)
View(cstree)
exjOnto <- sqldf("select * from cstree left join dict_all on cstree.concept_id = dict_all.concept_id")
exjOnto <- sqldf("select * from cstree left join dict_all on cstree.concept_id = dict_all.concept_id", drv="SQLite")
View(exjOnto)
write.table(exjOnto, paste0("~/Desktop/exjOnto.txt"),
sep="\t", eol="\n", quote=FALSE, row.names=FALSE, col.names=FALSE)
exjOnto$label <- tolower(exjOnto$label)
exjOnto$term_code <- tolower(exjOnto$term_code)
exjOnto$search_document <- tolower(exjOnto$search_document)
write.table(exjOnto, paste0("~/Desktop/exjOnto.txt"),
sep="\t", eol="\n", quote=FALSE, row.names=FALSE, col.names=FALSE)
for (i in 1:10) {
print i
}
for (i in 1:10) {
print i
}
for (i in 1:10) {
print 1
}
for (i in 1:10) {
print(i)
}
main <- read.table("~/rp//lmr.csv", sep="\t", stringsAsFactors=FALSE, fill=TRUE) # 542744 notes
table(main$V13)
View(main)
table(main$V13 == 1)
table(main$V15 == 1) # pri
table(main$V13 != 1 & main$V15 != 1)
load("~/git/udn/shiny/udn.RData")
View(udn)
load("~/Desktop/nlpAnalysis/concept_in_idash.RDS")
# get ctakes concept inside idash dataset
.packages <- c("data.table", "xml2", "plyr", "RMySQL", "sqldf")
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) suppressMessages(install.packages(.packages[!.inst], repos="http://cran.rstudio.com/"))
invisible(lapply(.packages, library, character.only=TRUE))
con <- dbConnect(MySQL(), user="mimic2", password="2CIMIM_v26", dbname="2015AA", host="safar.csail.mit.edu")
ExtractFirstCui <- function(filename) {
concept <- data.frame(item = character())
for (m in 1:length(filename)) {
xml <- readLines(filename[m])
idx <- which(grepl("UmlsConcept", xml))[1]
if (!is.na(idx)) { # if nothing before matching
xml <- xml[idx:length(xml)]
xml <- data.frame(item=xml, tag=0)
for (i in 1:nrow(xml)) {
if (grepl("UmlsConcept", xml[i, 1]) == TRUE &
grepl("UmlsConcept", xml[i, 1]) == grepl("UmlsConcept", xml[i+1, 1])) {
xml$tag[i+1] <- 1
}
}
xml <- subset(xml, xml$tag==0)
xml <- subset(xml, grepl("UmlsConcept", xml$item))
xml$tag <- 0
cuiInDoc <- data.frame(matrix(nrow=nrow(xml), ncol=0))
for (i in 1:nrow(xml)) {
cuiInDoc$snomed[i] <- gsub("(.*code=\")([0-9]+)(\" oid=.*)", "\\2", xml$item[i])
cuiInDoc$snomed_str[i] <- dbGetQuery(con, paste0("select STR from mrconso where SAB like 'SNOMEDCT_US' and CODE like '", cuiInDoc$snomed[i], "'"))
cuiInDoc$umls[i] <- gsub("(.*cui=\")(C[0-9]+)(\" tui=.*)", "\\2", xml$item[i])
cuiInDoc$umls_str[i] <- dbGetQuery(con, paste0("select STR from mrconso where CUI like '", cuiInDoc$umls[i], "'"))
cuiInDoc$tui[i] <- gsub("(.*tui=\")(T[0-9]+)(\".*)", "\\2", xml$item[i])
}
concept <- rbind(concept, cuiInDoc)
rm(cuiInDoc)
} else {
concept <- data.frame(snomed='noconcept', umls='noconcept', tui='noconcept')
}
}
return(concept)
}
dir <- "~/_data/_parsed/samplenotes_431/"
fileList <- list.files(dir)
concept_in_idash <- data.frame()
for (i in 1:length(fileList)) {
tmp <- ExtractFirstCui(paste0(dir, fileList[i]))
concept_in_idash <- rbind(concept_in_idash, tmp)
}
saveRDS(concept_in_idash, "concept_in_idash.RDS")
concept_in_idash = readRDS("concept_in_idash.RDS")
c <- concept_in_idash[duplicated(concept_in_idash$umls), ]
c <- c[!duplicated(c$snomed), ]
c <- c[order(c$umls, c$snomed), ]
View(c)
install.packages("rmongodb")
library(rmongodb)
mongo <- mongo.create()
mongo <- mongo.create()
mongo.is.connected(mongo)
mongo.count(mongo, "rmongodb.zips",
+             query=
'
{"state":"AL"}
'
)
mongo.count(mongo, "rmongodb.zips",
+             query=
'
{"state":"AL"}
'
)
mongo.count(mongo, "rmongodb.zips",query='{"state":"AL"}')
2 ^ 5
log(10)
log(5^9)
exp(log(5^4))
svd
iris
3 + 4
exp(log(4^3))
x <- 4 * 9
y <- c("Harvard", "MIT", "Beaver")
library(caret)
?train
model <- trian(Species ~ ., iris, method = "svmLinear")
model <- train(Species ~ ., iris, method = "svmLinear")
predict(model, iris)
pred <- predict(model, iris)
confusionMatrix(iris$Species, pred)
w**5
w**5
2**5
head(iris)
str(iris)
summary(iris)
is.character(3, "Harvard")
is.character(c(3, "Harvard"))
is.character(3)
is.integer(3.0)
is.integer(3)
is.numeric(3)
is.integer(3)
is.logical(3)
is.logical(1)
c(1, 2, 3)
c(1, 2, "a", "b")
seq(5, 100, 20)
rep(c(3, 5), 4)
rep(c(3, 5), each=4, length=10)
seq(5, 100, 20, lenght=3)
rep(c(3, 5), each=4, length=10)
seq(5, 100, 20, length=3)
seq(5, 100, 20, length=3)
rep(c(3, 5), each=4, length=10)
seq(5, 100, by=20, length=3)
seq(from=5, to=100, by=20, length=3)
seq(from=5, to=100, by=20)
rep(c(3, 5), each=4, length=10)
y[0]
y[1]
paste(y, "Adam")
x <- 4 * 9
y <- c("Harvard", "MIT", "Beaver")
# data type
is.character(3)
is.numeric(3)
is.integer(3)
is.complex(3)
is.logical(3)
NA
is.na()
na.omit()
read.csv()
read.table()
write.csv()
write.table()
c(1, 2, 3)
c(1, 2, "a", "b")
seq(from=5, to=100, by=20)
rep(c(3, 5), each=4, length=10)
y[1]
tolower(y)
toupper(y)
paste(y, "Adam")
paste("Adam", "Wright", sep="+")
paste("BMI", 701:705, sep=".", collapse="|")
strsplit("Adam is cool", " ")
grep(pattern="^a.*y$", x=c("ally", "awesome", "elly"), ignore.case=TRUE)
sub(pattern="^a.*y$", x=c("ally", "awesome", "elly"), ignore.case=TRUE)
sub(pattern="^a.*y$", replacement="NO" x=c("ally", "awesome", "elly"), ignore.case=TRUE)
sub(pattern="^a.*y$", replacement="NO", x=c("ally", "awesome", "elly"), ignore.case=TRUE)
x <- c(1, 2, 2, 6, 7, 6, 2, 5, 3)
factor(x)
matrix(c(1:25), nrow=5, ncol=5)
matrix(c(1:25), nrow=5, ncol=5, byrow=FALSE)
if (10 > 5) {
print("return 10")
} else {
print("return 5")
}
for (i in 1:100) {
print(i)
}
x <- 10
while (x > 5) {
print x
x -= 1
}
x <- 10
while (x > 5) {
print(x)
x -= 1
}
x <- 10
while (x > 5) {
print(x)
x <- x - 1
}
apply(iris$Sepal.Length, margin=1, FUN=mean)
apply(iris$Sepal.Length, FUN=mean)
iris$Sepal.Length
apply(iris$Sepal.Length, margin=0, FUN=mean)
apply(iris$Sepal.Length, margin=1, FUN=mean)
iris$Sepal.Length
apply(iris$Sepal.Length, margin=1, FUN=sum)
apply(iris$Sepal.Length, MARGIN=1, FUN=)
apply(iris$Sepal.Length, MARGIN=1, FUN=mean)
apply(iris$Sepal.Width, MARGIN=1, FUN=mean)
apply(iris$Sepal.Width, MARGIN=2, FUN=mean)
apply(iris$Sepal.Width, FUN=mean)
# create your function
f <- function(x) {
sum <- 0
if (x == 1 | x == 2) {
sum <- 1
} else {
sum <- x + f(x-1) + f (x-2)
}
}
#
f(4)
f <- function(x) {
sum <- 0
if (x == 1 | x == 2) {
sum <- 1
} else {
sum <- x + f(x-1) + f (x-2)
}
return(sum)
}
f(4)
print(c(f(1), f(2), f(3), f(4))
)#
# create your function
f <- function(x) {
sum <- 0
if (x == 1 | x == 2) {
sum <- 1
} else {
sum <- f(x-1) + f (x-2)
}
return(sum)
}
print(c(f(1), f(2), f(3), f(4))
print(c(f(1), f(2), f(3), f(4)))
print(c(f(1), f(2), f(3), f(4)))
f <- function(x) {
sum <- 0
if (x == 1 | x == 2) {
sum <- 1
} else {
sum <- f(x-1) + f (x-2)
}
return(sum)
}
f(10)
for (i in 1:10) print(f(i))
library(h2o)
# initialize h2o
h2o.removeAll()
h2o.init(nthreads=-1, max_mem_size="2G")
# iris
all <- read.table("/Users/weng/Desktop/combi/BSG_all/analysis/freqTbl.txt", sep="\t", header=T)
label <- read.table("/Users/weng/Desktop/combi/BSG_all/analysis/label.txt", sep="\t", header=F)
all$yLabel <- label[, 1]
all <- as.h2o(all)
y <- "yLabel"
x <- setdiff(names(all), y)
all[, y] <- as.factor(all[, y])
splits <- h2o.splitFrame(all, 0.9, seed=777)
dl <- h2o.deeplearning(x=x, y=y,
training_frame=all,
distribution = "AUTO",
activation = "RectifierWithDropout",
hidden = c(32,32,32),
input_dropout_ratio = 0.2,
balance_classes = TRUE,
sparse = TRUE,
l1 = 1e-5,
epochs = 10,
nfolds = 5)
all <- read.table("/Users/weng/Desktop/combi/BSG_all/analysis/freqTbl.txt", sep="\t", header=T)
label <- read.table("/Users/weng/Desktop/combi/BSG_all/analysis/label.txt", sep="\t", header=F)
all$yLabel <- label[, 1]
all <- as.h2o(all)
y <- "yLabel"
x <- setdiff(names(all), y)
all[, y] <- as.factor(all[, y])
splits <- h2o.splitFrame(all, 0.9, seed=777)
x <- foreach(a=1:3, b=rep(10, 3)) %do% (a + b)
mymat<-matrix(rep(seq(5), 4), ncol = 5)
apply(mymat, 1, sum)
apply(mymat, 2, sum)
View(mymat)
setwd("~/git/bmi701lab/")
for (k in 1:m) {if (!k %% 2)nextprint(k)}
library(foreac)
library(foreach)
x <- foreach(a=1:3, b=rep(10, 3)) %do% (a + b)
x
a = read.table("~/Desktop/GWASCatalogDump.txt", sep="\t")
a = read.table("~/Desktop/GWASCatalogDump.txt", sep=" ")
a = read.table("~/Desktop/GWASCatalogDump.txt", sep="\t", fill=T)
View(a)
a = read.table("~/Desktop/GWASCatalogDump.txt", sep="\t", fill=T, header=T)
View(a)
summary(a)
length(table(a$marker_accession))
